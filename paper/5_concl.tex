\section{\textbf{Conclusion}}

We have shown above that the AME framework for modeling dependent data dominates the standard approaches which use some form of a general linear model---typically a logit---to analyze dyadic data, especially in international relations. But are there any alternatives that have been developed? Three basic approaches have appeared as alternatives in the literature.\footnote{A good overview may be found in \cite{stewart:2014}, which proposes a variational estimation approach to latent network models.}
None of these approaches has as yet been widely employed nor even cited in the substantive literature, and each is mainly known inside of the network methodology community.  We discuss each of these approaches and briefly compare them to the AME approach. The takeaway is that based on simulation evidence, the AME approach also dominates these approaches in terms of recovering the data generating process and thus AME enables users to more accurately conduct inference on dependent data.\footnote{The detailed results are not presented herein.}


\subsection*{Cluster-Robust Variance Estimation}

\cite{aronow:etal:2015} discussed the problem of estimation of general linear models in the absence of $\simiid$ validity. In particular, they look at the so-called clustering in dyadic data. This is the clustering of errors that occur because multiple dyads share individual members. They develop a sandwich style estimator which leaves untouched the parameters, opting instead for a nonparametric approach which attempts to correct the variance estimates across dyads.  They do not compare their approach to AME or other strategies to explicitly estimate parametric effects in networks. Instead, they examine a spatial lag approach and general mixed effects models that abide by the $\simiid$ assumption.  Their basic equation is 
\begin{eqnarray*}
Y_{ij} = \mathbf{X}_{ij}^\intercal \beta + \varepsilon_{ij}
\end{eqnarray*}
and the important parameter is $\beta$, defined in the standard way, via an appropriate estimator (they use OLS).  They assert that a random sampling of dyads that do not share a member will be uncorrelated, i.e., $\text{Cov}(\varepsilon_d,\varepsilon_{d'}) \equiv 0$, where $d'$ is the set of dyads that do not share members. Following this leads to the conclusion that the variance in the full sample of the dyadic, independent data and the dyadic error contains a known bias, part of which is a dyad specific variance component and another part is due to repeated, shared memberships in dyads. $\hat{\beta}$ is shown to be consistent, i.e., that as the number of \emph{dyads} increase to infinity, it converges in probability to its true value. 

The variance calculations used by Aronow et al basically decompose the variance into three parts, the cluster robust variance (all dyads with unit $i$, assuming all others to be 
$\simiid$), the separate cluster robust variance of the repeated dyads, and clustered robust variance of all dyads, assuming they are all independent.  Using simulation, they demonstrate that as sample size increases, this formula for calculating the variance-covariance matrix will decline as the number of nodes in the network increase and approach its true value.  

This approach focuses on the standard errors, needed for significance testing, but ignores the bias introduced into the regression coefficients, as discussed above.  Nor does it provide any way to access the higher-order network effects, a point that Aronow et alia make in their article, noting that it is only targeted at first-order, dyadic (not higher level) dependencies. The cluster robust variance approach simply provides a fix to the estimated standard errors.  In this sense, it treats the dependent data as having dependencies that are a nuisance, in the statistical sense.
%One of the main problems with dependent data is that it takes more data to calculate basic quantities accurately. This is true even for a simple t-test \citep{ward:gleditsch:2008}. 

Cluster-robust vriance estimation is not designed to answer the same questions as AME.  As shown in the original article, it does provide a way to  estimate standard errors (in a sitution with only dyadic dependence) that substantially improves over the standard logistic regression approach.  However, it ignores the higher-order dependencies which are the focus of the AME model.  


%Isn't brandon stewart overview a better place to start?


\subsection*{Choice Based Sampling}

Poast \citeyear{poast:2010,poast:2016} doesn't really offer a way to estimate dyadic data in the presence of independence,
``I am not presenting an alternative procedure for modeling such spatial, strategic, temporal,
or monadic interdependencies in the data.'' Instead, he argues that multilateral events are poorly represented or misrepresented by dyadic data.  In a sense, he is arguing against dyadic data.  He creates an artificial database that is triadic and from it generates a process that combines the capabilities of the three actors in each triad into a ratio that drives whether an alliance is formed among all three actors.  Then these triadic data are converted into a dyadic format. He then uses a logit regression framework to show that with the omniscient data in the triadic case, logit regression can recover the true value of the data generating process, but logit, as applied to the dyadic construction of the triadic data, produces estimates that are inflated. 

Poast's solution to this is called choice-based sampling, ``[t]he sampling method entails constructing a data set containing all observations for which the dependent variable is coded with a positive value, along with a random sample of observations for which the dependent variable is coded 0'' (page 410). This new sample is then estimated with a rare-events logit regression. His results (page 412) show that their is a small bias (about $1\%$) using the dyadic approach compared to the alternatives he proposes.  As one moves from triadic to \textit{5-adic}, the divergence from the analysis of the dyadic data becomes substantially larger. Poast doesn't address the underlying issue of how to properly estimate dependent data, but raises the question whether dyadic data are capable of representing multi-adic data generating processes.  Unfortunately, adjudicating this with an approach (logit regression) that itself is known to be incapable of capturing the higher-order aspects of the data generating process is, itself, problematic on first principles.  

However, how does Poast's approach compare to AME? We found in simulations structured like those reported herein run with the k-adic model that the k-adic model was dramatically worse at recovering the real data generating process than AME. 


\subsection*{Multiple Regression Quadratic Assignment Procedure}

\citet{erikson:pinto:2014} base their approach on MRQAP developed by 
Krackhardt (1988), \nocite{krackhart:1988} an approach from network studies that draws upon the fact that networks have repeated observations, which induces some correlation of observations leading to bias in standard errors of general linear models of these data. MRQAP randomly permutes the rows and columns of the data, creating multiple datasets which are then each analyzed in the standard way to generate a sampling distribution of all possible (but not observed) networks from the observed data. Herein, the data are randomly permuted on the assumption that the errors are exchangeable.  Many permutations are created and models are run on all of them, then the distributions of tests statistics (not parameters) are examined. They find in their reanalysis that ``the randomization results show that conventional t-tests are inappropriate for
testing hypotheses on dyad-year data because they rely on highly overconfident standard errors'' (page 462).  This shows that in dyadic data analysis with general linear models, especially with hundreds of thousands of observations, the standard t-test is polyannaish in finding significant relations.  One simple fix is MRQAP, which addresses---again---the standard errors. This approach does not focus on the underlying data generating process, and is based on an approach to modeling dependent data that is known to produce bias and ignore dependencies.  In our simulations of the MRQAP model, we find that it does not recover the data generating process as well as AME. This is quite due in part to the fact that it treats the dependencies as nuisance to be eliminated rather than focused on explicitly as with AME. 



\subsection*{Summary}
International relations is about the interactions, relationships, and dependencies among countries or other important international actors. This is particularly true of scholarship in the tradition of the Correlates of War Project, but it is by no means limited to it.\footnote{See \cite{singer:1972} for an early description of the project and also see the project's Web site for an history and more recent efforts \url{http://www.correlatesofwar.org/}.} Many scholars have debated the use and abuse of dyadic data.\footnote{One recent on-line symposium can be found at \url{http://bit.ly/2wB2hab}.} Research published as recently as 2017 and a broad survey of the IR literature makes it clear that scholars find dyadic data to be an essential touchstone in the study of international relations \citep{erikson:pinto:2014,aronow:etal:2015}.

At the same time, we know that research designs focusing on the statistical analysis of dyadic data quickly go astray if the dyadic data are assumed to be iid.  Virtually all of the standard statistical models---ordinary least squares and logistic regressions, to name a few---fail if the data are not conditionally independent. This fact has been accepted as it relates to temporal dependencies, but adoption of methods to account for network dependencies have seen less progress. By definition dyadic data are not iid and thus the standard approaches cannot be used cavalierly to analyze these data.  \citet{signorino:1999} showed why this is true of models of strategic interaction, but it is more broadly true of models that employ dyadic data.  We show that the AME framework can be employed to account for the statistical issues that arise when studying dyadic data.

To explore this approach in the context of international relations we have presented two analyses. The first is a simulation where the characteristics of the network are known. This shows that when there are unobserved dependencies, the AME approach is less biased in terms of parameter estimation compared to the standard approach employed in international relations to study dyadic data (i.e., GLM models). The second analysis is a replication of recent studies that use a broad range of dyadic data to draw inferences about international relations.  These studies have been replicated with the original research designs, each of which used a statistical method that assumes the dyadic data are all independent from one another.  We then re-analyzed each study using the AME model.  In every case, we found that the AME approach provided a) increased precision of estimation, b) better out-of-sample fit, and c) evidence of 1st-, 2nd-, and 3rd-order dependencies that were overlooked in the original studies.\footnote{The Appendix contains performance data on all of these replications, as well as sample code illustrating how to undertake AME analysis using \texttt{amen}.} In several cases, the new approach overturns the basic findings of the original research.

It is no longer necessary to assume that the interesting, innate interdependencies in relational data about international relations can be ignored. Nor do they have to be approximated with \textit{ad hoc}, incomplete solutions that purport to control for dependencies (such as modifying the post-estimation standard errors of the estimated coefficients \citep{king:roberts:2014}). Instead, the interdependencies may be addressed directly with additive and multiplicative effects in the context of a generalized linear model that provides more reliable inferences, better out-of-sample predictive performance, and new substantive insights. 